```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris
from sklearn.metrics import accuracy_score
from sklearn.model_selection import KFold
import numpy as np
```


```python
iris = load_iris()
dt_clf = DecisionTreeClassifier(random_state=156)
kfold = KFold(n_splits=5)
```


```python
cv_accuracy = []
n_iter = 0

for train_index,test_index in kfold.split(iris.data):
    # print(train_index)
    # print(test_index)
    X_train,X_test = iris.data[train_index],iris.data[test_index]
```


```python
X_train,X_test
```




    (array([[5.1, 3.5, 1.4, 0.2],
            [4.9, 3. , 1.4, 0.2],
            [4.7, 3.2, 1.3, 0.2],
            [4.6, 3.1, 1.5, 0.2],
            [5. , 3.6, 1.4, 0.2],
            [5.4, 3.9, 1.7, 0.4],
            [4.6, 3.4, 1.4, 0.3],
            [5. , 3.4, 1.5, 0.2],
            [4.4, 2.9, 1.4, 0.2],
            [4.9, 3.1, 1.5, 0.1],
            [5.4, 3.7, 1.5, 0.2],
            [4.8, 3.4, 1.6, 0.2],
            [4.8, 3. , 1.4, 0.1],
            [4.3, 3. , 1.1, 0.1],
            [5.8, 4. , 1.2, 0.2],
            [5.7, 4.4, 1.5, 0.4],
            [5.4, 3.9, 1.3, 0.4],
            [5.1, 3.5, 1.4, 0.3],
            [5.7, 3.8, 1.7, 0.3],
            [5.1, 3.8, 1.5, 0.3],
            [5.4, 3.4, 1.7, 0.2],
            [5.1, 3.7, 1.5, 0.4],
            [4.6, 3.6, 1. , 0.2],
            [5.1, 3.3, 1.7, 0.5],
            [4.8, 3.4, 1.9, 0.2],
            [5. , 3. , 1.6, 0.2],
            [5. , 3.4, 1.6, 0.4],
            [5.2, 3.5, 1.5, 0.2],
            [5.2, 3.4, 1.4, 0.2],
            [4.7, 3.2, 1.6, 0.2],
            [4.8, 3.1, 1.6, 0.2],
            [5.4, 3.4, 1.5, 0.4],
            [5.2, 4.1, 1.5, 0.1],
            [5.5, 4.2, 1.4, 0.2],
            [4.9, 3.1, 1.5, 0.2],
            [5. , 3.2, 1.2, 0.2],
            [5.5, 3.5, 1.3, 0.2],
            [4.9, 3.6, 1.4, 0.1],
            [4.4, 3. , 1.3, 0.2],
            [5.1, 3.4, 1.5, 0.2],
            [5. , 3.5, 1.3, 0.3],
            [4.5, 2.3, 1.3, 0.3],
            [4.4, 3.2, 1.3, 0.2],
            [5. , 3.5, 1.6, 0.6],
            [5.1, 3.8, 1.9, 0.4],
            [4.8, 3. , 1.4, 0.3],
            [5.1, 3.8, 1.6, 0.2],
            [4.6, 3.2, 1.4, 0.2],
            [5.3, 3.7, 1.5, 0.2],
            [5. , 3.3, 1.4, 0.2],
            [7. , 3.2, 4.7, 1.4],
            [6.4, 3.2, 4.5, 1.5],
            [6.9, 3.1, 4.9, 1.5],
            [5.5, 2.3, 4. , 1.3],
            [6.5, 2.8, 4.6, 1.5],
            [5.7, 2.8, 4.5, 1.3],
            [6.3, 3.3, 4.7, 1.6],
            [4.9, 2.4, 3.3, 1. ],
            [6.6, 2.9, 4.6, 1.3],
            [5.2, 2.7, 3.9, 1.4],
            [5. , 2. , 3.5, 1. ],
            [5.9, 3. , 4.2, 1.5],
            [6. , 2.2, 4. , 1. ],
            [6.1, 2.9, 4.7, 1.4],
            [5.6, 2.9, 3.6, 1.3],
            [6.7, 3.1, 4.4, 1.4],
            [5.6, 3. , 4.5, 1.5],
            [5.8, 2.7, 4.1, 1. ],
            [6.2, 2.2, 4.5, 1.5],
            [5.6, 2.5, 3.9, 1.1],
            [5.9, 3.2, 4.8, 1.8],
            [6.1, 2.8, 4. , 1.3],
            [6.3, 2.5, 4.9, 1.5],
            [6.1, 2.8, 4.7, 1.2],
            [6.4, 2.9, 4.3, 1.3],
            [6.6, 3. , 4.4, 1.4],
            [6.8, 2.8, 4.8, 1.4],
            [6.7, 3. , 5. , 1.7],
            [6. , 2.9, 4.5, 1.5],
            [5.7, 2.6, 3.5, 1. ],
            [5.5, 2.4, 3.8, 1.1],
            [5.5, 2.4, 3.7, 1. ],
            [5.8, 2.7, 3.9, 1.2],
            [6. , 2.7, 5.1, 1.6],
            [5.4, 3. , 4.5, 1.5],
            [6. , 3.4, 4.5, 1.6],
            [6.7, 3.1, 4.7, 1.5],
            [6.3, 2.3, 4.4, 1.3],
            [5.6, 3. , 4.1, 1.3],
            [5.5, 2.5, 4. , 1.3],
            [5.5, 2.6, 4.4, 1.2],
            [6.1, 3. , 4.6, 1.4],
            [5.8, 2.6, 4. , 1.2],
            [5. , 2.3, 3.3, 1. ],
            [5.6, 2.7, 4.2, 1.3],
            [5.7, 3. , 4.2, 1.2],
            [5.7, 2.9, 4.2, 1.3],
            [6.2, 2.9, 4.3, 1.3],
            [5.1, 2.5, 3. , 1.1],
            [5.7, 2.8, 4.1, 1.3],
            [6.3, 3.3, 6. , 2.5],
            [5.8, 2.7, 5.1, 1.9],
            [7.1, 3. , 5.9, 2.1],
            [6.3, 2.9, 5.6, 1.8],
            [6.5, 3. , 5.8, 2.2],
            [7.6, 3. , 6.6, 2.1],
            [4.9, 2.5, 4.5, 1.7],
            [7.3, 2.9, 6.3, 1.8],
            [6.7, 2.5, 5.8, 1.8],
            [7.2, 3.6, 6.1, 2.5],
            [6.5, 3.2, 5.1, 2. ],
            [6.4, 2.7, 5.3, 1.9],
            [6.8, 3. , 5.5, 2.1],
            [5.7, 2.5, 5. , 2. ],
            [5.8, 2.8, 5.1, 2.4],
            [6.4, 3.2, 5.3, 2.3],
            [6.5, 3. , 5.5, 1.8],
            [7.7, 3.8, 6.7, 2.2],
            [7.7, 2.6, 6.9, 2.3],
            [6. , 2.2, 5. , 1.5]]),
     array([[6.9, 3.2, 5.7, 2.3],
            [5.6, 2.8, 4.9, 2. ],
            [7.7, 2.8, 6.7, 2. ],
            [6.3, 2.7, 4.9, 1.8],
            [6.7, 3.3, 5.7, 2.1],
            [7.2, 3.2, 6. , 1.8],
            [6.2, 2.8, 4.8, 1.8],
            [6.1, 3. , 4.9, 1.8],
            [6.4, 2.8, 5.6, 2.1],
            [7.2, 3. , 5.8, 1.6],
            [7.4, 2.8, 6.1, 1.9],
            [7.9, 3.8, 6.4, 2. ],
            [6.4, 2.8, 5.6, 2.2],
            [6.3, 2.8, 5.1, 1.5],
            [6.1, 2.6, 5.6, 1.4],
            [7.7, 3. , 6.1, 2.3],
            [6.3, 3.4, 5.6, 2.4],
            [6.4, 3.1, 5.5, 1.8],
            [6. , 3. , 4.8, 1.8],
            [6.9, 3.1, 5.4, 2.1],
            [6.7, 3.1, 5.6, 2.4],
            [6.9, 3.1, 5.1, 2.3],
            [5.8, 2.7, 5.1, 1.9],
            [6.8, 3.2, 5.9, 2.3],
            [6.7, 3.3, 5.7, 2.5],
            [6.7, 3. , 5.2, 2.3],
            [6.3, 2.5, 5. , 1.9],
            [6.5, 3. , 5.2, 2. ],
            [6.2, 3.4, 5.4, 2.3],
            [5.9, 3. , 5.1, 1.8]]))




```python
iris = load_iris()
dt_clf = DecisionTreeClassifier(random_state=156)
kfold = KFold(n_splits=5)
```


```python
cv_accuracy = []
n_iter = 0

for train_index,test_index in kfold.split(iris.data):
    # print(train_index)
    # print(test_index)
    X_train,X_test = iris.data[train_index],iris.data[test_index]
    y_train,y_test = iris.target[train_index],iris.target[test_index]
    dt_clf.fit(X_train,y_train)
    pred = dt_clf.predict(X_test)
    n_iter += 1
    accuracy = accuracy_score(y_test,pred)
    cv_accuracy.append(accuracy)
    print(n_iter,accuracy)
```

    1 1.0
    2 0.9666666666666667
    3 0.8666666666666667
    4 0.9333333333333333
    5 0.7333333333333333
    


```python
np.round(np.mean(cv_accuracy),4)
```




    0.9




```python
iris = load_iris()
dt_clf = DecisionTreeClassifier(random_state=156)
kfold = KFold(n_splits=5,shuffle=True)
```


```python
cv_accuracy = []
n_iter = 0

for train_index,test_index in kfold.split(iris.data):
    # print(train_index)
    # print(test_index)
    X_train,X_test = iris.data[train_index],iris.data[test_index]
    y_train,y_test = iris.target[train_index],iris.target[test_index]
    dt_clf.fit(X_train,y_train)
    pred = dt_clf.predict(X_test)
    n_iter += 1
    accuracy = accuracy_score(y_test,pred)
    cv_accuracy.append(accuracy)
    print(n_iter,accuracy)
    print(y_test)
```

    1 0.9333333333333333
    [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]
    2 0.9333333333333333
    [0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]
    3 0.9666666666666667
    [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2]
    4 0.9333333333333333
    [0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2]
    5 0.9666666666666667
    [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2]
    


```python
np.round(np.mean(cv_accuracy),4)
```




    0.9467




```python
data = load_iris(as_frame=True)
```


```python
data.target.value_counts()
```




    0    50
    1    50
    2    50
    Name: target, dtype: int64




```python
kfold = KFold(n_splits=3,shuffle=True)
cv_accuracy = []
n_iter = 0

for train_index,test_index in kfold.split(iris.data):
    X_train,X_test = iris.data[train_index],iris.data[test_index]
    y_train,y_test = iris.target[train_index],iris.target[test_index]
    dt_clf.fit(X_train,y_train)
    pred = dt_clf.predict(X_test)
    n_iter += 1
    accuracy = accuracy_score(y_test,pred)
    cv_accuracy.append(accuracy)
    print(n_iter,accuracy)
    print(y_test)
```

    1 0.98
    [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2
     2 2 2 2 2 2 2 2 2 2 2 2 2]
    2 0.94
    [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2
     2 2 2 2 2 2 2 2 2 2 2 2 2]
    3 0.94
    [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2
     2 2 2 2 2 2 2 2 2 2 2 2 2]
    


```python
from sklearn.model_selection import StratifiedKFold
```


```python
kfold = StratifiedKFold(n_splits=3,shuffle=False)
cv_accuracy = []
n_iter = 0

iris = load_iris(as_frame=True)

for train_index,test_index in kfold.split(iris.data,iris.target):
    X_train,X_test = iris.data.iloc[train_index],iris.data.iloc[test_index]
    y_train,y_test = iris.target.iloc[train_index],iris.target.iloc[test_index]
    
    print('학습데이터 분포:',y_train.value_counts())
    dt_clf.fit(X_train,y_train)
    pred = dt_clf.predict(X_test)
    n_iter += 1
    accuracy = accuracy_score(y_test,pred)
    cv_accuracy.append(accuracy)
    print(n_iter,accuracy)
    print(y_test)
```

    학습데이터 분포: 2    34
    0    33
    1    33
    Name: target, dtype: int64
    1 0.98
    0      0
    1      0
    2      0
    3      0
    4      0
    5      0
    6      0
    7      0
    8      0
    9      0
    10     0
    11     0
    12     0
    13     0
    14     0
    15     0
    16     0
    50     1
    51     1
    52     1
    53     1
    54     1
    55     1
    56     1
    57     1
    58     1
    59     1
    60     1
    61     1
    62     1
    63     1
    64     1
    65     1
    66     1
    100    2
    101    2
    102    2
    103    2
    104    2
    105    2
    106    2
    107    2
    108    2
    109    2
    110    2
    111    2
    112    2
    113    2
    114    2
    115    2
    Name: target, dtype: int32
    학습데이터 분포: 1    34
    0    33
    2    33
    Name: target, dtype: int64
    2 0.94
    17     0
    18     0
    19     0
    20     0
    21     0
    22     0
    23     0
    24     0
    25     0
    26     0
    27     0
    28     0
    29     0
    30     0
    31     0
    32     0
    33     0
    67     1
    68     1
    69     1
    70     1
    71     1
    72     1
    73     1
    74     1
    75     1
    76     1
    77     1
    78     1
    79     1
    80     1
    81     1
    82     1
    116    2
    117    2
    118    2
    119    2
    120    2
    121    2
    122    2
    123    2
    124    2
    125    2
    126    2
    127    2
    128    2
    129    2
    130    2
    131    2
    132    2
    Name: target, dtype: int32
    학습데이터 분포: 0    34
    1    33
    2    33
    Name: target, dtype: int64
    3 0.98
    34     0
    35     0
    36     0
    37     0
    38     0
    39     0
    40     0
    41     0
    42     0
    43     0
    44     0
    45     0
    46     0
    47     0
    48     0
    49     0
    83     1
    84     1
    85     1
    86     1
    87     1
    88     1
    89     1
    90     1
    91     1
    92     1
    93     1
    94     1
    95     1
    96     1
    97     1
    98     1
    99     1
    133    2
    134    2
    135    2
    136    2
    137    2
    138    2
    139    2
    140    2
    141    2
    142    2
    143    2
    144    2
    145    2
    146    2
    147    2
    148    2
    149    2
    Name: target, dtype: int32
    


```python
kfold = StratifiedKFold(n_splits=3,shuffle=False)
cv_accuracy = []
n_iter = 0

iris = load_iris(as_frame=True)

for train_index,test_index in kfold.split(iris.data,iris.target):
    X_train,X_test = iris.data.iloc[train_index],iris.data.iloc[test_index]
    y_train,y_test = iris.target.iloc[train_index],iris.target.iloc[test_index]
    
    # print('학습데이터 분포:',y_train.value_counts())
    dt_clf.fit(X_train,y_train)
    pred = dt_clf.predict(X_test)
    n_iter += 1
    accuracy = accuracy_score(y_test,pred)
    cv_accuracy.append(accuracy)
    print(n_iter,accuracy)
```

    1 0.98
    2 0.94
    3 0.98
    


```python
from sklearn.model_selection import cross_val_score
```


```python
dt_clf= DecisionTreeClassifier(random_state=156)
iris = load_iris()
cross_val_score(dt_clf,iris.data,iris.target,cv=3)
```




    array([0.98, 0.94, 0.98])




```python
grid_param = {
    'max_depth':[1, 2, 3],
    'min_samples_split':[2, 3],
}
```


```python
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split
import pandas as pd
```


```python
iris = load_iris()
X_train,X_test,y_train,y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=121)
```


```python
dtree = DecisionTreeClassifier()
grid_dtree = GridSearchCV(dtree,grid_param,cv=3, refit=True)
```


```python
grid_dtree.fit(X_train,y_train)
```




    GridSearchCV(cv=3, estimator=DecisionTreeClassifier(),
                 param_grid={'max_depth': [1, 2, 3], 'min_samples_split': [2, 3]})




```python
grid_dtree.predict(X_test)
```




    array([1, 2, 1, 0, 0, 1, 1, 1, 1, 2, 2, 1, 1, 0, 0, 2, 1, 0, 2, 0, 2, 2,
           1, 1, 1, 1, 0, 0, 2, 2])




```python
df = pd.DataFrame(grid_dtree.cv_results_)
```


```python
df.columns
```




    Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',
           'param_max_depth', 'param_min_samples_split', 'params',
           'split0_test_score', 'split1_test_score', 'split2_test_score',
           'mean_test_score', 'std_test_score', 'rank_test_score'],
          dtype='object')




```python
df[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score','split2_test_score']]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>params</th>
      <th>mean_test_score</th>
      <th>rank_test_score</th>
      <th>split0_test_score</th>
      <th>split1_test_score</th>
      <th>split2_test_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>{'max_depth': 1, 'min_samples_split': 2}</td>
      <td>0.700000</td>
      <td>5</td>
      <td>0.700</td>
      <td>0.7</td>
      <td>0.70</td>
    </tr>
    <tr>
      <th>1</th>
      <td>{'max_depth': 1, 'min_samples_split': 3}</td>
      <td>0.700000</td>
      <td>5</td>
      <td>0.700</td>
      <td>0.7</td>
      <td>0.70</td>
    </tr>
    <tr>
      <th>2</th>
      <td>{'max_depth': 2, 'min_samples_split': 2}</td>
      <td>0.958333</td>
      <td>3</td>
      <td>0.925</td>
      <td>1.0</td>
      <td>0.95</td>
    </tr>
    <tr>
      <th>3</th>
      <td>{'max_depth': 2, 'min_samples_split': 3}</td>
      <td>0.958333</td>
      <td>3</td>
      <td>0.925</td>
      <td>1.0</td>
      <td>0.95</td>
    </tr>
    <tr>
      <th>4</th>
      <td>{'max_depth': 3, 'min_samples_split': 2}</td>
      <td>0.975000</td>
      <td>1</td>
      <td>0.975</td>
      <td>1.0</td>
      <td>0.95</td>
    </tr>
    <tr>
      <th>5</th>
      <td>{'max_depth': 3, 'min_samples_split': 3}</td>
      <td>0.975000</td>
      <td>1</td>
      <td>0.975</td>
      <td>1.0</td>
      <td>0.95</td>
    </tr>
  </tbody>
</table>
</div>




```python
grid_dtree.best_params_
```




    {'max_depth': 3, 'min_samples_split': 2}




```python
grid_dtree.best_score_
```




    0.975




```python
pred = grid_dtree.best_estimator_.predict(X_test)
```


```python
accuracy_score(y_test,pred)
```




    0.9666666666666667


