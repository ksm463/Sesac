{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMkaZMbAHBL3rrLKh+UNMrP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["## 전이 학습\n","* 사전 학습된 네트워크의 가중치를 사용. 크게 세 가지\n","* 기본 과정 : 입력 -> 모델 -> 분류기 -> 출력\n","1. 모델을 변형하지 않고 사용\n","2. 모델 분류기 재학습\n","3. 모델 일부를 재학습시키기\n","* 전체 재학습은 시간이 많이 걸리므로 일부를 조정해서 이용한다."],"metadata":{"id":"v4AB4qrMx3e2"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":318},"id":"GlfQ_OnTwVvR","executionInfo":{"status":"ok","timestamp":1670990210249,"user_tz":-540,"elapsed":20706,"user":{"displayName":"Sung Min Kim","userId":"02834507779081291840"}},"outputId":"e07bdfcd-ab15-44d0-8437-df9c35b524bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 5s 0us/step\n"]},{"output_type":"execute_result","data":{"text/plain":["(35000, 1)"]},"metadata":{},"execution_count":1},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["from keras.datasets import cifar10\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","plt.imshow(x_test[0])\n","x_mean = np.mean(x_train,axis=(0,1,2))\n","x_std = np.std(x_train, axis = (0,1,2))\n","\n","x_train = (x_train - x_mean) / x_std\n","x_test = (x_test - x_mean) / x_std\n","\n","x_train, x_val, y_train, y_val = train_test_split(x_train,y_train,test_size=0.3,random_state=777)\n","y_train.shape"]},{"cell_type":"code","source":["x_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mjfP7_eS0sfB","executionInfo":{"status":"ok","timestamp":1670990980500,"user_tz":-540,"elapsed":294,"user":{"displayName":"Sung Min Kim","userId":"02834507779081291840"}},"outputId":"232105e8-638e-41e2-f4f1-f3b90403cdcf"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(35000, 32, 32, 3)"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["### 전이 학습 설정하기"],"metadata":{"id":"u1IwUCao2VdQ"}},{"cell_type":"code","source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(horizontal_flip=True, \n","                                   zoom_range=0.2, \n","                                   width_shift_range=0.1, \n","                                   height_shift_range=0.1, \n","                                   rotation_range=30, \n","                                   fill_mode='nearest') \n","\n","val_datagen = ImageDataGenerator()\n","\n","batch_size = 32\n","\n","train_generator = train_datagen.flow(x_train,y_train,batch_size=batch_size)\n","val_generator = val_datagen.flow(x_val,y_val,batch_size=batch_size)"],"metadata":{"id":"RhPKw0YFxtDQ","executionInfo":{"status":"ok","timestamp":1670990486742,"user_tz":-540,"elapsed":393,"user":{"displayName":"Sung Min Kim","userId":"02834507779081291840"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Activation, BatchNormalization\n","from keras.optimizers import Adam\n","\n","from keras.applications import VGG16\n","\n","vgg16 = VGG16(include_top=False,input_shape=(32, 32, 3))\n","vgg16.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JXFZYofEyllk","executionInfo":{"status":"ok","timestamp":1670991034271,"user_tz":-540,"elapsed":4454,"user":{"displayName":"Sung Min Kim","userId":"02834507779081291840"}},"outputId":"2eb38bda-0360-45de-bea0-a3ea31bec423"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 0s 0us/step\n","Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n","                                                                 \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["### 모델 동결 해제하기"],"metadata":{"id":"-ZpiVOtm2M_g"}},{"cell_type":"code","source":["for layer in vgg16.layers[:-4]: # 모델 끝 4개 층만 선택\n","  layer.trainable = False # 동결을 해제제"],"metadata":{"id":"KL6WPhZ702pz","executionInfo":{"status":"ok","timestamp":1670991356583,"user_tz":-540,"elapsed":3,"user":{"displayName":"Sung Min Kim","userId":"02834507779081291840"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### 전이 학습을 통해 학습하기"],"metadata":{"id":"8SbWo3f72uhm"}},{"cell_type":"code","source":["model = Sequential([\n","    vgg16,\n","    Flatten(),\n","    Dense(256),\n","    BatchNormalization(),\n","    Activation('relu'),\n","    Dense(10, activation='softmax')\n","])\n","\n","model.compile(optimizer = Adam(1e-4), loss = 'sparse_categorical_crossentropy',metrics=['acc'])\n","\n","def get_step(train_len, batch_size):\n","  if(train_len % batch_size > 0):\n","    return train_len // batch_size + 1\n","  else:\n","    return train_len // batch_size\n","\n","history = model.fit(train_generator,\n","                    epochs=100,\n","                    steps_per_epoch=get_step(len(x_train),batch_size),\n","                    validation_data=val_generator,\n","                    validation_steps = get_step(len(x_val), batch_size))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RQfUtu3-2J_Z","executionInfo":{"status":"ok","timestamp":1670994681506,"user_tz":-540,"elapsed":2945044,"user":{"displayName":"Sung Min Kim","userId":"02834507779081291840"}},"outputId":"ea1425ce-70f8-4084-a27f-bce1d146facc"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1094/1094 [==============================] - 39s 27ms/step - loss: 1.1232 - acc: 0.1066 - val_loss: 0.9254 - val_acc: 0.0801\n","Epoch 2/100\n","1094/1094 [==============================] - 29s 27ms/step - loss: 0.9237 - acc: 0.1017 - val_loss: 1.0233 - val_acc: 0.0944\n","Epoch 3/100\n","1094/1094 [==============================] - 31s 28ms/step - loss: 0.8482 - acc: 0.1021 - val_loss: 0.7274 - val_acc: 0.1223\n","Epoch 4/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.7972 - acc: 0.1049 - val_loss: 0.7824 - val_acc: 0.0863\n","Epoch 5/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.7713 - acc: 0.1042 - val_loss: 0.7694 - val_acc: 0.0774\n","Epoch 6/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.7327 - acc: 0.1036 - val_loss: 0.7249 - val_acc: 0.0872\n","Epoch 7/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.7002 - acc: 0.1028 - val_loss: 0.7604 - val_acc: 0.0889\n","Epoch 8/100\n","1094/1094 [==============================] - 29s 27ms/step - loss: 0.6862 - acc: 0.1036 - val_loss: 0.6829 - val_acc: 0.0937\n","Epoch 9/100\n","1094/1094 [==============================] - 29s 27ms/step - loss: 0.6573 - acc: 0.1030 - val_loss: 0.6741 - val_acc: 0.0921\n","Epoch 10/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.6342 - acc: 0.1027 - val_loss: 0.6682 - val_acc: 0.0860\n","Epoch 11/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.6124 - acc: 0.1028 - val_loss: 0.7338 - val_acc: 0.0914\n","Epoch 12/100\n","1094/1094 [==============================] - 29s 27ms/step - loss: 0.5837 - acc: 0.1029 - val_loss: 0.6624 - val_acc: 0.1075\n","Epoch 13/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.5648 - acc: 0.1034 - val_loss: 0.6429 - val_acc: 0.1089\n","Epoch 14/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.5460 - acc: 0.1022 - val_loss: 0.7116 - val_acc: 0.0957\n","Epoch 15/100\n","1094/1094 [==============================] - 30s 27ms/step - loss: 0.5241 - acc: 0.1033 - val_loss: 0.6498 - val_acc: 0.1003\n","Epoch 16/100\n","1094/1094 [==============================] - 29s 27ms/step - loss: 0.5094 - acc: 0.1024 - val_loss: 0.6435 - val_acc: 0.0935\n","Epoch 17/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.4940 - acc: 0.1030 - val_loss: 0.6541 - val_acc: 0.0895\n","Epoch 18/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.4793 - acc: 0.1023 - val_loss: 0.7099 - val_acc: 0.0850\n","Epoch 19/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.4558 - acc: 0.1026 - val_loss: 0.6685 - val_acc: 0.1013\n","Epoch 20/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.4433 - acc: 0.1026 - val_loss: 0.6734 - val_acc: 0.0885\n","Epoch 21/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.4298 - acc: 0.1022 - val_loss: 0.6916 - val_acc: 0.0985\n","Epoch 22/100\n","1094/1094 [==============================] - 30s 27ms/step - loss: 0.4174 - acc: 0.1027 - val_loss: 0.7218 - val_acc: 0.0895\n","Epoch 23/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.4020 - acc: 0.1024 - val_loss: 0.6917 - val_acc: 0.1029\n","Epoch 24/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.3852 - acc: 0.1018 - val_loss: 0.6456 - val_acc: 0.0971\n","Epoch 25/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.3721 - acc: 0.1017 - val_loss: 0.6781 - val_acc: 0.0975\n","Epoch 26/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.3651 - acc: 0.1023 - val_loss: 0.6523 - val_acc: 0.0901\n","Epoch 27/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.3525 - acc: 0.1025 - val_loss: 0.7449 - val_acc: 0.0925\n","Epoch 28/100\n","1094/1094 [==============================] - 29s 27ms/step - loss: 0.3403 - acc: 0.1025 - val_loss: 0.7459 - val_acc: 0.0991\n","Epoch 29/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.3247 - acc: 0.1028 - val_loss: 0.7486 - val_acc: 0.0937\n","Epoch 30/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.3230 - acc: 0.1023 - val_loss: 0.7377 - val_acc: 0.0898\n","Epoch 31/100\n","1094/1094 [==============================] - 28s 26ms/step - loss: 0.3069 - acc: 0.1023 - val_loss: 0.7511 - val_acc: 0.1002\n","Epoch 32/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.3065 - acc: 0.1016 - val_loss: 0.7443 - val_acc: 0.0883\n","Epoch 33/100\n","1094/1094 [==============================] - 29s 27ms/step - loss: 0.2918 - acc: 0.1021 - val_loss: 0.7615 - val_acc: 0.0917\n","Epoch 34/100\n","1094/1094 [==============================] - 29s 27ms/step - loss: 0.2819 - acc: 0.1017 - val_loss: 0.7445 - val_acc: 0.0892\n","Epoch 35/100\n","1094/1094 [==============================] - 30s 27ms/step - loss: 0.2806 - acc: 0.1017 - val_loss: 0.7865 - val_acc: 0.0869\n","Epoch 36/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.2667 - acc: 0.1023 - val_loss: 0.7423 - val_acc: 0.0889\n","Epoch 37/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.2609 - acc: 0.1016 - val_loss: 0.7722 - val_acc: 0.0953\n","Epoch 38/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.2576 - acc: 0.1013 - val_loss: 0.7579 - val_acc: 0.0941\n","Epoch 39/100\n","1094/1094 [==============================] - 29s 27ms/step - loss: 0.2412 - acc: 0.1017 - val_loss: 0.7939 - val_acc: 0.0987\n","Epoch 40/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.2430 - acc: 0.1025 - val_loss: 0.8261 - val_acc: 0.0903\n","Epoch 41/100\n","1094/1094 [==============================] - 30s 27ms/step - loss: 0.2356 - acc: 0.1019 - val_loss: 0.8564 - val_acc: 0.0867\n","Epoch 42/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.2379 - acc: 0.1016 - val_loss: 0.7903 - val_acc: 0.0989\n","Epoch 43/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.2251 - acc: 0.1025 - val_loss: 0.7659 - val_acc: 0.0863\n","Epoch 44/100\n","1094/1094 [==============================] - 29s 27ms/step - loss: 0.2222 - acc: 0.1021 - val_loss: 0.8367 - val_acc: 0.0897\n","Epoch 45/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.2164 - acc: 0.1017 - val_loss: 0.8442 - val_acc: 0.0958\n","Epoch 46/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.2081 - acc: 0.1019 - val_loss: 0.8297 - val_acc: 0.0917\n","Epoch 47/100\n","1094/1094 [==============================] - 29s 27ms/step - loss: 0.2046 - acc: 0.1015 - val_loss: 0.8542 - val_acc: 0.0928\n","Epoch 48/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.2079 - acc: 0.1019 - val_loss: 0.8617 - val_acc: 0.0951\n","Epoch 49/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.2000 - acc: 0.1020 - val_loss: 0.8783 - val_acc: 0.0878\n","Epoch 50/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1983 - acc: 0.1020 - val_loss: 0.8454 - val_acc: 0.0953\n","Epoch 51/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1873 - acc: 0.1023 - val_loss: 0.8572 - val_acc: 0.0943\n","Epoch 52/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1922 - acc: 0.1019 - val_loss: 0.8840 - val_acc: 0.0925\n","Epoch 53/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1828 - acc: 0.1024 - val_loss: 0.8536 - val_acc: 0.0771\n","Epoch 54/100\n","1094/1094 [==============================] - 29s 27ms/step - loss: 0.1796 - acc: 0.1023 - val_loss: 0.8774 - val_acc: 0.0925\n","Epoch 55/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1767 - acc: 0.1019 - val_loss: 0.8597 - val_acc: 0.0965\n","Epoch 56/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1754 - acc: 0.1018 - val_loss: 0.8955 - val_acc: 0.0958\n","Epoch 57/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1687 - acc: 0.1023 - val_loss: 0.8777 - val_acc: 0.0927\n","Epoch 58/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1697 - acc: 0.1019 - val_loss: 0.9341 - val_acc: 0.0861\n","Epoch 59/100\n","1094/1094 [==============================] - 29s 27ms/step - loss: 0.1644 - acc: 0.1020 - val_loss: 0.9230 - val_acc: 0.0856\n","Epoch 60/100\n","1094/1094 [==============================] - 29s 27ms/step - loss: 0.1621 - acc: 0.1016 - val_loss: 0.8926 - val_acc: 0.0951\n","Epoch 61/100\n","1094/1094 [==============================] - 30s 28ms/step - loss: 0.1625 - acc: 0.1020 - val_loss: 0.8954 - val_acc: 0.0915\n","Epoch 62/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1547 - acc: 0.1020 - val_loss: 0.8672 - val_acc: 0.0881\n","Epoch 63/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1532 - acc: 0.1019 - val_loss: 0.9040 - val_acc: 0.0961\n","Epoch 64/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1492 - acc: 0.1015 - val_loss: 0.9294 - val_acc: 0.1021\n","Epoch 65/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1510 - acc: 0.1018 - val_loss: 0.8497 - val_acc: 0.0940\n","Epoch 66/100\n","1094/1094 [==============================] - 29s 27ms/step - loss: 0.1498 - acc: 0.1021 - val_loss: 0.8973 - val_acc: 0.0865\n","Epoch 67/100\n","1094/1094 [==============================] - 29s 27ms/step - loss: 0.1471 - acc: 0.1017 - val_loss: 0.9375 - val_acc: 0.0899\n","Epoch 68/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1412 - acc: 0.1019 - val_loss: 0.8779 - val_acc: 0.1035\n","Epoch 69/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1328 - acc: 0.1020 - val_loss: 0.9605 - val_acc: 0.0898\n","Epoch 70/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1438 - acc: 0.1015 - val_loss: 0.8817 - val_acc: 0.0945\n","Epoch 71/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1389 - acc: 0.1020 - val_loss: 0.9232 - val_acc: 0.0886\n","Epoch 72/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1321 - acc: 0.1018 - val_loss: 0.9600 - val_acc: 0.0970\n","Epoch 73/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1307 - acc: 0.1019 - val_loss: 0.9581 - val_acc: 0.0926\n","Epoch 74/100\n","1094/1094 [==============================] - 30s 27ms/step - loss: 0.1255 - acc: 0.1018 - val_loss: 0.9524 - val_acc: 0.0966\n","Epoch 75/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1296 - acc: 0.1013 - val_loss: 0.9040 - val_acc: 0.1030\n","Epoch 76/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1309 - acc: 0.1023 - val_loss: 0.9377 - val_acc: 0.0887\n","Epoch 77/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1221 - acc: 0.1018 - val_loss: 1.1087 - val_acc: 0.1040\n","Epoch 78/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1298 - acc: 0.1023 - val_loss: 0.9283 - val_acc: 0.0972\n","Epoch 79/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1245 - acc: 0.1021 - val_loss: 0.9741 - val_acc: 0.0874\n","Epoch 80/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1199 - acc: 0.1018 - val_loss: 0.9564 - val_acc: 0.0979\n","Epoch 81/100\n","1094/1094 [==============================] - 30s 27ms/step - loss: 0.1197 - acc: 0.1019 - val_loss: 0.9692 - val_acc: 0.1055\n","Epoch 82/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1168 - acc: 0.1022 - val_loss: 0.9408 - val_acc: 0.0879\n","Epoch 83/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1165 - acc: 0.1022 - val_loss: 0.9622 - val_acc: 0.0863\n","Epoch 84/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1158 - acc: 0.1018 - val_loss: 0.9181 - val_acc: 0.0922\n","Epoch 85/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1139 - acc: 0.1020 - val_loss: 0.9435 - val_acc: 0.0904\n","Epoch 86/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1145 - acc: 0.1022 - val_loss: 1.0401 - val_acc: 0.0867\n","Epoch 87/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1171 - acc: 0.1025 - val_loss: 0.9640 - val_acc: 0.0889\n","Epoch 88/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1076 - acc: 0.1018 - val_loss: 1.0060 - val_acc: 0.0927\n","Epoch 89/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1074 - acc: 0.1020 - val_loss: 1.0566 - val_acc: 0.0877\n","Epoch 90/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1108 - acc: 0.1017 - val_loss: 1.0224 - val_acc: 0.0865\n","Epoch 91/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1042 - acc: 0.1021 - val_loss: 0.9907 - val_acc: 0.0999\n","Epoch 92/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1064 - acc: 0.1025 - val_loss: 0.9853 - val_acc: 0.0883\n","Epoch 93/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1037 - acc: 0.1021 - val_loss: 0.9927 - val_acc: 0.0935\n","Epoch 94/100\n","1094/1094 [==============================] - 30s 27ms/step - loss: 0.1027 - acc: 0.1022 - val_loss: 1.0342 - val_acc: 0.0918\n","Epoch 95/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1033 - acc: 0.1019 - val_loss: 0.9990 - val_acc: 0.0903\n","Epoch 96/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1062 - acc: 0.1017 - val_loss: 0.9936 - val_acc: 0.0868\n","Epoch 97/100\n","1094/1094 [==============================] - 29s 27ms/step - loss: 0.0961 - acc: 0.1021 - val_loss: 0.9708 - val_acc: 0.1011\n","Epoch 98/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1023 - acc: 0.1021 - val_loss: 0.9753 - val_acc: 0.0968\n","Epoch 99/100\n","1094/1094 [==============================] - 29s 26ms/step - loss: 0.1001 - acc: 0.1019 - val_loss: 0.9992 - val_acc: 0.1010\n","Epoch 100/100\n","1094/1094 [==============================] - 30s 27ms/step - loss: 0.0990 - acc: 0.1019 - val_loss: 1.0171 - val_acc: 0.0897\n"]}]}]}